{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e86a0d",
   "metadata": {},
   "source": [
    "# 빠른 시작 가이드 - Azure AI Foundry\n",
    "\n",
    "이 노트북은 Azure AI Foundry에 대한 실습 소개를 제공합니다:\n",
    "1. AI 프로젝트 클라이언트 초기화\n",
    "2. 사용 가능한 모델 나열\n",
    "3. 간단한 채팅 완료 요청을 생성\n",
    "4. 기본 AI 에이전트 생성\n",
    "5. 기본 오류 시나리오 다루기\n",
    "\n",
    "## 전제 조건\n",
    "- 이전 notebook에서 환경 설정 완료\n",
    "- Azure 자격 증명 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b65a7d",
   "metadata": {},
   "source": [
    "## 필수 라이브러리 및 설정 가져오기\n",
    "\n",
    "다음 코드의 내용은 다음을 수행합니다:\n",
    "1. 인증 및 AI 프로젝트에 필요한 Azure SDK 라이브러리를 가져옵니다\n",
    "2. 환경 변수 및 JSON 처리를 위한 표준 Python 라이브러리를 가져옵니다\n",
    "3. DefaultAzureCredential을 사용하여 Azure 자격 증명을 초기화\n",
    "   - 로그인한 Azure CLI 자격 증명을 자동으로 사용\n",
    "   - 또는 환경 변수 또는 매니지드 아이덴티티와 같은 다른 인증 방법을 사용할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1a355de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Initialize credentials\n",
    "credential = DefaultAzureCredential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd18d4ef",
   "metadata": {},
   "source": [
    "## AI Project Client 초기화\n",
    "\n",
    "> **참고:** 계속 진행하기 전에 다음 사항을 확인하세요:\n",
    "> 1. 루트 디렉토리의 `.env.example` 파일을 `.env` 로 복사합니다.\n",
    "> 2. `.env` 파일에서 프로젝트 연결 문자열을 업데이트합니다.\n",
    "> 3. Azure AI Foundry에 허브 및 프로젝트를 프로비전하여 배포해서 가지고 있어야 합니다.\n",
    "\n",
    "프로젝트의 설정 아래에서 [Azure AI Foundry](https://ai.azure.com)프로젝트 연결 문자열을 찾을 수 있습니다:\n",
    "\n",
    "<img src=\"proj-conn-string.png\" alt=\"Project Connection String Location\" width=\"600\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e5ebd2",
   "metadata": {},
   "source": [
    "## AI Project Client 생성하기\n",
    "\n",
    "다음 코드에서는 `.env` 파일의 연결 문자열을 사용하여 AI 프로젝트 클라이언트를 만들겠습니다.\n",
    "> **Note:** This example uses the synchronous client. For higher performance scenarios, you can also create an asynchronous client by importing `asyncio` and using the async methods from `AIProjectClient`.\n",
    "\n",
    "The client will be used to:\n",
    "- Connect to your Azure AI Project using the connection string\n",
    "- Authenticate using Azure credentials\n",
    "- Enable making inference requests to your deployed models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b96006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Load environment variables\n",
    "notebook_path = Path().absolute()\n",
    "parent_dir = notebook_path.parent\n",
    "load_dotenv(parent_dir / '.env')\n",
    "\n",
    "try:\n",
    "    client = AIProjectClient.from_connection_string(\n",
    "        conn_str=os.getenv(\"PROJECT_CONNECTION_STRING\"),\n",
    "        credential=credential\n",
    "    )\n",
    "    print(\"✓ Successfully initialized AIProjectClient\")\n",
    "except Exception as e:\n",
    "    print(f\"× Error initializing client: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d77e602",
   "metadata": {},
   "source": [
    "## Create a Simple Completion\n",
    "Let's try a basic completion request:\n",
    "\n",
    "Now that we have an authenticated client, let's use it to make a chat completion request.\n",
    "The code below demonstrates how to:\n",
    "1. Get a ChatCompletionsClient from the azure-ai-inference package\n",
    "2. Use it to make a simple completion request\n",
    "\n",
    "We'll use the MODEL_DEPLOYMENT_NAME from our `.env` file, making it easy to switch between different\n",
    "deployed models without changing code. This could be an Azure OpenAI model, Microsoft model, or other providers\n",
    "that support chat completions.\n",
    "\n",
    "> Note: Make sure you have the azure-ai-inference package installed (from requirements.txt or as mentioned in [README.md](../README.md#-quick-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3774ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.inference.models import UserMessage\n",
    "\n",
    "model_deployment_name = os.getenv(\"MODEL_DEPLOYMENT_NAME\")\n",
    "\n",
    "try:\n",
    "    chat_client = client.inference.get_chat_completions_client()\n",
    "    response = chat_client.complete(\n",
    "        model=model_deployment_name, \n",
    "        messages=[UserMessage(content=\"How to be healthy in one sentence?\")]\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7864f9",
   "metadata": {},
   "source": [
    "## Create a simple Agent\n",
    "\n",
    "Using AI Agent Service, we can create a simple agent to answer health related questions.\n",
    "\n",
    "Let's explore Azure AI Agent Service, a powerful tool for building intelligent agents.\n",
    "\n",
    "Azure AI Agent Service is a fully managed service that helps developers build, deploy, and scale AI agents\n",
    "without managing infrastructure. It combines large language models with tools that allow agents to:\n",
    "- Answer questions using RAG (Retrieval Augmented Generation)\n",
    "- Perform actions through tool calling \n",
    "- Automate complex workflows\n",
    "\n",
    "The code below demonstrates how to:\n",
    "1. Create an agent with a code interpreter tool\n",
    "2. Create a conversation thread\n",
    "3. Send a message requesting BMI analysis \n",
    "4. Process the request and get results\n",
    "5. Save any generated visualizations\n",
    "\n",
    "The agent will use the model specified in our .env file (MODEL_DEPLOYMENT_NAME) and will have access\n",
    "to a code interpreter tool for creating visualizations. This showcases how agents can combine\n",
    "natural language understanding with computational capabilities.\n",
    "\n",
    "> The visualization will be saved as a PNG file in the same folder as this notebook.\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afb12b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects.models import CodeInterpreterTool\n",
    "\n",
    "try:\n",
    "    # Initialize the Code Interpreter Tool\n",
    "    code_interpreter = CodeInterpreterTool()\n",
    "    \n",
    "    # Create an AI agent with the code interpreter tool\n",
    "    agent = client.agents.create_agent(\n",
    "        model=model_deployment_name,\n",
    "        name=\"bmi-calculator\",\n",
    "        instructions=(\n",
    "            \"You are a health analyst who calculates BMI using US metrics (pounds, feet/inches). \"\n",
    "            \"Use average US female measurements: 5'4\\\" (69 inches) and 130 pounds. \"\n",
    "            \"Create a visualization showing where this BMI falls on the scale.\"\n",
    "        ),\n",
    "        tools=code_interpreter.definitions,\n",
    "        tool_resources=code_interpreter.resources,\n",
    "    )\n",
    "    \n",
    "    # Create a new conversation thread\n",
    "    thread = client.agents.create_thread()\n",
    "    \n",
    "    # Create a message requesting BMI analysis and visualization\n",
    "    message = client.agents.create_message(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=(\n",
    "            \"Calculate BMI for an average US female (5'4\\\", 130 lbs). \"\n",
    "            \"Create a visualization showing where this BMI falls on the standard BMI scale from 15 to 35. \"\n",
    "            \"Include the standard BMI categories (Underweight, Normal, Overweight, Obese) in the visualization.\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Process the request by creating and running a thread run\n",
    "    run = client.agents.create_and_process_run(thread_id=thread.id, assistant_id=agent.id)\n",
    "    \n",
    "    # Retrieve and save any generated visualizations\n",
    "    messages = client.agents.list_messages(thread_id=thread.id)\n",
    "    for image_content in messages.image_contents:\n",
    "        file_name = f\"bmi_analysis_{image_content.image_file.file_id}.png\"\n",
    "        client.agents.save_file(file_id=image_content.image_file.file_id, file_name=file_name)\n",
    "        print(f\"Analysis saved as: {file_name}\")\n",
    "    \n",
    "    # Print the analysis text from the assistant\n",
    "    print(f\"Messages: {messages}\")\n",
    "    if last_msg := messages.get_last_text_message_by_role(\"assistant\"):\n",
    "        print(f\"Analysis: {last_msg.text.value}\")\n",
    "    \n",
    "    # Cleanup by deleting the agent\n",
    "    client.agents.delete_agent(agent.id)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro-health-file-search",
      "metadata": {},
      "source": [
        "# ğŸ ê±´ê°• ë¦¬ì†ŒìŠ¤ ê²€ìƒ‰ ì—ì´ì „íŠ¸ íŠœí† ë¦¬ì–¼ ğŸ\n",
        "\n",
        "**ê±´ê°• ë¦¬ì†ŒìŠ¤ ê²€ìƒ‰ ì—ì´ì „íŠ¸** ììŠµì„œì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤! **Azure AI Foundry** SDKë¥¼ ì‚¬ìš©í•˜ì—¬ ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ë¹Œë“œí•˜ê² ìŠµë‹ˆë‹¤:\n",
        "\n",
        "1. ê±´ê°• ë° ë ˆì‹œí”¼ íŒŒì¼ì„ ë²¡í„° ìŠ¤í† ì–´ì— **ì—…ë¡œë“œ**í•©ë‹ˆë‹¤.\n",
        "2. **íŒŒì¼ ê²€ìƒ‰** ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ **ì—ì´ì „íŠ¸ë¥¼ ìƒì„±**í•©ë‹ˆë‹¤.\n",
        "3. ê´€ë ¨ ì‹ë‹¨ ì •ë³´ë¥¼ **ê²€ìƒ‰**í•©ë‹ˆë‹¤.\n",
        "4. ê±´ê°• ë° ì›°ë¹™ ê´€ë ¨ ì§ˆë¬¸ì— **ë‹µë³€**í•©ë‹ˆë‹¤(ë©´ì±… ì¡°í•­ í¬í•¨!).\n",
        "\n",
        "### âš ï¸ ì¤‘ìš” ì˜ë£Œ ê³ ì§€ ì‚¬í•­ âš ï¸\n",
        "> **ì´ ë…¸íŠ¸ì˜ ëª¨ë“  ê±´ê°• ì •ë³´ëŠ” ì¼ë°˜ì ì¸ êµìœ¡ ëª©ì ìœ¼ë¡œë§Œ ì œê³µë˜ë©° ì „ë¬¸ì ì¸ ì˜í•™ì  ì¡°ì–¸, ì§„ë‹¨ ë˜ëŠ” ì¹˜ë£Œë¥¼ ëŒ€ì‹ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.** ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ í•­ìƒ ìê²©ì„ ê°–ì¶˜ ì˜ë£Œ ì „ë¬¸ê°€ì˜ ì¡°ì–¸ì„ êµ¬í•˜ì„¸ìš”.\n",
        "\n",
        "## ì „ì œ ì¡°ê±´\n",
        "- Agent ê¸°ë³¸ ë…¸íŠ¸ë¶ ì „ì²´ - [1-basics.ipynb](1-basics.ipynb)\n",
        "- **ì—­í• **  \n",
        "  1. Azure AI íŒŒìš´ë“œë¦¬ í”„ë¡œì íŠ¸ì˜ **Azure AI Developer** \n",
        "  2. í”„ë¡œì íŠ¸ì˜ ì €ì¥ì†Œ ê³„ì •ì˜ **Storage Blob Data Contributor** \n",
        "  3. ìì²´ ê²€ìƒ‰ ë¦¬ì†ŒìŠ¤ì™€ í•¨ê»˜ í‘œì¤€ ì—ì´ì „íŠ¸ ì„¤ì •ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, í•´ë‹¹ ë¦¬ì†ŒìŠ¤ì—  **Cognitive Search Data Contributor**ë„ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "\n",
        "\n",
        "## ê²€ìƒ‰ì„ ì‹œì‘í•´ ë´…ì‹œë‹¤!\n",
        "ëª‡ ê°€ì§€ ìƒ˜í”Œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³ , ì´ë¥¼ ìœ„í•œ ë²¡í„° ì €ì¥ì†Œë¥¼ ë§Œë“  ë‹¤ìŒ, ì´ëŸ¬í•œ ë¦¬ì†ŒìŠ¤ì—ì„œ ì‹ë‹¨ ì§€ì¹¨, ë ˆì‹œí”¼ ë“±ì„ ê²€ìƒ‰í•  ìˆ˜ ìˆëŠ” ì—ì´ì „íŠ¸ë¥¼ ê°€ë™í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì¦ê²¨ë³´ì„¸ìš”!\n",
        "\n",
        "<img src=\"./seq-diagrams/3-file-search.png\" width=\"30%\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "initial-setup",
      "metadata": {},
      "source": [
        "## 1. ì´ˆê¸° ì„¤ì •\n",
        "ì—¬ê¸°ì„œëŠ” í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ê°€ì ¸ì˜¤ê³ , `.env`ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•˜ê³ , **AIProjectClient**ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤. í•´ë´…ì‹œë‹¤! ğŸ‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "init-client-code",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.projects import AIProjectClient\n",
        "from azure.ai.projects.models import (\n",
        "    FileSearchTool,\n",
        "    FilePurpose,\n",
        "    MessageTextContent,\n",
        "    MessageRole\n",
        ")\n",
        "\n",
        "# Load environment variables from parent .env\n",
        "notebook_path = Path().absolute()\n",
        "parent_dir = notebook_path.parent\n",
        "load_dotenv(parent_dir / '.env')\n",
        "\n",
        "# Initialize AIProjectClient\n",
        "try:\n",
        "    project_client = AIProjectClient.from_connection_string(\n",
        "        credential=DefaultAzureCredential(),\n",
        "        conn_str=os.environ.get(\"PROJECT_CONNECTION_STRING\")\n",
        "    )\n",
        "    print(\"âœ… Successfully initialized AIProjectClient\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error initializing project client: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "create-sample-resources",
      "metadata": {},
      "source": [
        "## 2. ìƒ˜í”Œ íŒŒì¼ ì¤€ë¹„í•˜ê¸° ğŸ²ğŸ—’\n",
        "ë ˆì‹œí”¼ì™€ ê°€ì´ë“œë¼ì¸ì„ ìœ„í•œ ë”ë¯¸ .md íŒŒì¼ì„ ë§Œë“¤ê² ìŠµë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ê²€ìƒ‰ì„ ìœ„í•´ ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "create-files-code",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_sample_files():\n",
        "    recipes_md = (\n",
        "        \"\"\"# Healthy Recipes Database\\n\\n\"\n",
        "        \"## Gluten-Free Recipes\\n\"\n",
        "        \"1. Quinoa Bowl\\n\"\n",
        "        \"   - Ingredients: quinoa, vegetables, olive oil\\n\"\n",
        "        \"   - Instructions: Cook quinoa, add vegetables\\n\\n\"\n",
        "        \"2. Rice Pasta with Vegetables\\n\"\n",
        "        \"   - Ingredients: rice pasta, mixed vegetables\\n\"\n",
        "        \"   - Instructions: Boil pasta, sautÃ© vegetables\\n\\n\"\n",
        "        \"## Diabetic-Friendly Recipes\\n\"\n",
        "        \"1. Low-Carb Stir Fry\\n\"\n",
        "        \"   - Ingredients: chicken, vegetables, tamari sauce\\n\"\n",
        "        \"   - Instructions: Cook chicken, add vegetables\\n\\n\"\n",
        "        \"2. Greek Salad\\n\"\n",
        "        \"   - Ingredients: cucumber, tomatoes, feta, olives\\n\"\n",
        "        \"   - Instructions: Chop vegetables, combine\\n\\n\"\n",
        "        \"## Heart-Healthy Recipes\\n\"\n",
        "        \"1. Baked Salmon\\n\"\n",
        "        \"   - Ingredients: salmon, lemon, herbs\\n\"\n",
        "        \"   - Instructions: Season salmon, bake\\n\\n\"\n",
        "        \"2. Mediterranean Bowl\\n\"\n",
        "        \"   - Ingredients: chickpeas, vegetables, tahini\\n\"\n",
        "        \"   - Instructions: Combine ingredients\\n\"\"\"\n",
        "    )\n",
        "\n",
        "    guidelines_md = (\n",
        "        \"\"\"# Dietary Guidelines\\n\\n\"\n",
        "        \"## General Guidelines\\n\"\n",
        "        \"- Eat a variety of foods\\n\"\n",
        "        \"- Control portion sizes\\n\"\n",
        "        \"- Stay hydrated\\n\\n\"\n",
        "        \"## Special Diets\\n\"\n",
        "        \"1. Gluten-Free Diet\\n\"\n",
        "        \"   - Avoid wheat, barley, rye\\n\"\n",
        "        \"   - Focus on naturally gluten-free foods\\n\\n\"\n",
        "        \"2. Diabetic Diet\\n\"\n",
        "        \"   - Monitor carbohydrate intake\\n\"\n",
        "        \"   - Choose low glycemic foods\\n\\n\"\n",
        "        \"3. Heart-Healthy Diet\\n\"\n",
        "        \"   - Limit saturated fats\\n\"\n",
        "        \"   - Choose lean proteins\\n\"\"\"\n",
        "    )\n",
        "\n",
        "    # Save to local .md files\n",
        "    with open(\"recipes.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(recipes_md)\n",
        "    with open(\"guidelines.md\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(guidelines_md)\n",
        "\n",
        "    print(\"ğŸ“„ Created sample resource files: recipes.md, guidelines.md\")\n",
        "    return [\"recipes.md\", \"guidelines.md\"]\n",
        "\n",
        "sample_files = create_sample_files()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "note-above-step-3",
      "metadata": {},
      "source": [
        "#### âœ¨ ê²€ìƒ‰ ê¶Œí•œì— ëŒ€í•œ ì°¸ê³  ì‚¬í•­\n",
        "ë²¡í„° ìŠ¤í† ì–´ë¥¼ ë§Œë“¤ ë•Œ Azure AI ê²€ìƒ‰ ë¦¬ì†ŒìŠ¤ì— **Cognitive Search Data Contributor** ì—­í• ë„ ìˆì–´ì•¼ í•©ë‹ˆë‹¤(ìì²´ ê²€ìƒ‰ ë¦¬ì†ŒìŠ¤ì™€ í•¨ê»˜ í‘œì¤€ ì—ì´ì „íŠ¸ ì„¤ì •ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°). ì´ ì—­í• ì´ ì—†ìœ¼ë©´ **Forbidden** ì˜¤ë¥˜ê°€ ë°œìƒí•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. ê¶Œí•œ êµ¬ì„±ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [Authentication Setup](../../1-introduction/1-authentication.ipynb#4-add-agent-service-permissions) ì„ ì°¸ì¡°í•˜ì„¸ìš”.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "create-vector-store",
      "metadata": {},
      "source": [
        "## 3. ë²¡í„° ìŠ¤í† ì–´ ë§Œë“¤ê¸° ğŸ“š\n",
        "ìƒˆë¡œ ë§Œë“  íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ê²€ìƒ‰ì„ ìœ„í•´ í•˜ë‚˜ì˜ ë²¡í„° ìŠ¤í† ëŸ¬ë¡œ ê·¸ë£¹í™”í•©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ agentê°€ ë‚˜ì¤‘ì— ê´€ë ¨ í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vector-store-code",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_vector_store(files, store_name=\"my_health_resources\"):\n",
        "    try:\n",
        "        # Step 1: Upload files to Azure AI Agent service\n",
        "        # Each file needs to be uploaded individually and we'll collect their IDs\n",
        "        uploaded_ids = []\n",
        "        for fp in files:\n",
        "            # upload_file_and_poll ensures the upload is complete before continuing\n",
        "            # FilePurpose.AGENTS tells the service these files are for agent usage\n",
        "            upl = project_client.agents.upload_file_and_poll(\n",
        "                file_path=fp,\n",
        "                purpose=FilePurpose.AGENTS\n",
        "            )\n",
        "            uploaded_ids.append(upl.id)\n",
        "            print(f\"âœ… Uploaded: {fp} -> File ID: {upl.id}\")\n",
        "\n",
        "        # Step 2: Create a vector store from the uploaded files\n",
        "        # A vector store converts text into numerical vectors for semantic search\n",
        "        # create_vector_store_and_poll waits until indexing is complete\n",
        "        vs = project_client.agents.create_vector_store_and_poll(\n",
        "            file_ids=uploaded_ids,  # Pass all our uploaded file IDs\n",
        "            name=store_name         # Give our vector store a friendly name\n",
        "        )\n",
        "        print(f\"ğŸ‰ Created vector store '{store_name}', ID: {vs.id}\")\n",
        "        return vs, uploaded_ids\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error creating vector store: {e}\")\n",
        "        return None, []\n",
        "\n",
        "# Initialize empty variables to store our vector store and file IDs\n",
        "vector_store, file_ids = None, []\n",
        "\n",
        "# If we successfully created sample files earlier, create a vector store from them\n",
        "if sample_files:\n",
        "    vector_store, file_ids = create_vector_store(sample_files, \"health_resources_example\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "create-agent-file-search",
      "metadata": {},
      "source": [
        "## 4. ê±´ê°• ë¦¬ì†ŒìŠ¤ ì—ì´ì „íŠ¸ ìƒì„±í•˜ê¸° ğŸ”\n",
        "ìƒˆë¡œ ë§Œë“  ë²¡í„° ìŠ¤í† ì–´ë¥¼ ê°€ë¦¬í‚¤ëŠ” **FileSearchTool**ë¥¼ ì‚¬ìš©í•  ì˜ˆì •ì…ë‹ˆë‹¤. ë‹¤ìŒ ê³ ì§€ ì‚¬í•­, ì‹ì´ìš”ë²• ë„ì›€ë§ ë“±ì— ëŒ€í•œ ì§€ì¹¨ì´ í¬í•¨ëœ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "create-agent-code",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_health_resource_agent(vstore_id):\n",
        "    try:\n",
        "        # Create a FileSearchTool that will allow our agent to search through documents\n",
        "        # FileSearchTool uses the vector store we created earlier to perform semantic search\n",
        "        # This means the agent can find relevant content even if the exact words don't match\n",
        "        file_search_tool = FileSearchTool(vector_store_ids=[vstore_id])\n",
        "\n",
        "        # Create an AI agent that will use our search tool and follow specific instructions\n",
        "        # The agent combines:\n",
        "        # 1. A base LLM model (specified in environment variables or defaults to gpt-4o-mini)\n",
        "        # 2. The ability to search our health documents using the FileSearchTool\n",
        "        # 3. Custom instructions that shape how it responds to questions\n",
        "        agent = project_client.agents.create_agent(\n",
        "            # Specify which LLM model to use - fallback to gpt-4o-mini if not set\n",
        "            model=os.environ.get(\"MODEL_DEPLOYMENT_NAME\", \"gpt-4o-mini\"),\n",
        "            \n",
        "            # Give our agent a descriptive name\n",
        "            name=\"health-search-agent\",\n",
        "            \n",
        "            # These instructions act like a personality and rule set for our agent\n",
        "            # They ensure consistent, responsible health advice\n",
        "            instructions=\"\"\"\n",
        "                You are a health resource advisor with access to dietary and recipe files.\n",
        "                You:\n",
        "                1. Always present disclaimers (you're not a doctor!)\n",
        "                2. Provide references to the files when possible\n",
        "                3. Focus on general nutrition or recipe tips.\n",
        "                4. Encourage professional consultation for more detailed advice.\n",
        "            \"\"\",\n",
        "            \n",
        "            # Connect the search tool's interface definition and required resources\n",
        "            # This gives the agent the ability to actually perform searches\n",
        "            tools=file_search_tool.definitions,\n",
        "            tool_resources=file_search_tool.resources\n",
        "        )\n",
        "        print(f\"ğŸ‰ Created health resource agent, ID: {agent.id}\")\n",
        "        return agent\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error creating health resource agent: {e}\")\n",
        "        return None\n",
        "\n",
        "# Initialize our agent variable\n",
        "health_agent = None\n",
        "\n",
        "# Only create the agent if we successfully created a vector store earlier\n",
        "if vector_store:\n",
        "    health_agent = create_health_resource_agent(vector_store.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "health-search-conversation",
      "metadata": {},
      "source": [
        "## 5. ê±´ê°• ê´€ë ¨ ìë£Œ ê²€ìƒ‰ ğŸ‹ï¸ğŸ‘©â€ğŸ³\n",
        "ìƒˆ ëŒ€í™” ìŠ¤ë ˆë“œë¥¼ ë§Œë“¤ê³  â€œGluten-free recipe ideas?â€ ë˜ëŠ” â€œHeart-healthy meal plan?â€ê³¼ ê°™ì€ ì§ˆë¬¸ì„ í•©ë‹ˆë‹¤.ì—ì´ì „íŠ¸ê°€ ë²¡í„° ìŠ¤í† ì–´ì—ì„œ íŒŒì¼ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ì—¬ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ìŠµë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "search-code",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_search_thread(agent):\n",
        "    try:\n",
        "        # In Azure AI Agent service, conversations happen in \"threads\"\n",
        "        # A thread maintains the context and history of a conversation\n",
        "        # Here we create a new empty thread to start a fresh conversation\n",
        "        thread = project_client.agents.create_thread()\n",
        "        print(f\"ğŸ“ Created new search thread, ID: {thread.id}\")\n",
        "        return thread\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error creating search thread: {e}\")\n",
        "        return None\n",
        "\n",
        "def ask_search_question(thread_id, agent_id, user_question):\n",
        "    try:\n",
        "        # First, we add the user's question as a message to the thread\n",
        "        # This is like typing a message in a chat interface\n",
        "        message = project_client.agents.create_message(\n",
        "            thread_id=thread_id,\n",
        "            role=\"user\",  # Specifies this message is from the user\n",
        "            content=user_question\n",
        "        )\n",
        "        print(f\"ğŸ” Searching: '{user_question}'\")\n",
        "\n",
        "        # Next, we create and process a \"run\" - this is where the magic happens!\n",
        "        # The agent will:\n",
        "        # 1. Read the user's question\n",
        "        # 2. Use the FileSearchTool to search our health documents\n",
        "        # 3. Generate a helpful response based on the search results\n",
        "        run = project_client.agents.create_and_process_run(\n",
        "            thread_id=thread_id,\n",
        "            assistant_id=agent_id\n",
        "        )\n",
        "        print(f\"ğŸ¤– Run finished with status: {run.status}\")\n",
        "        if run.last_error:\n",
        "            print(f\"Error details: {run.last_error}\")\n",
        "        return run\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error searching question: {e}\")\n",
        "        return None\n",
        "\n",
        "# Now let's test our search functionality!\n",
        "# First check if we have our health agent available\n",
        "if health_agent:\n",
        "    # Create a new conversation thread\n",
        "    search_thread = create_search_thread(health_agent)\n",
        "\n",
        "    if search_thread:\n",
        "        # Define some test questions that demonstrate different types of health queries\n",
        "        # The agent will search our uploaded health documents to answer these\n",
        "        queries = [\n",
        "            \"Could you suggest a gluten-free lunch recipe?\",\n",
        "            \"Show me some heart-healthy meal ideas.\",\n",
        "            \"What guidelines do you have for someone with diabetes?\"\n",
        "        ]\n",
        "\n",
        "        # Process each query one at a time\n",
        "        # The agent will maintain conversation context between questions\n",
        "        for q in queries:\n",
        "            ask_search_question(search_thread.id, health_agent.id, q)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "view-search-results",
      "metadata": {},
      "source": [
        "## 6. ê²°ê³¼ ë° ì¸ìš© ë³´ê¸° ğŸ“„\n",
        "ëŒ€í™” ìŠ¤ë ˆë“œë¥¼ ì½ê³  ì—ì´ì „íŠ¸ê°€ ì–´ë–»ê²Œ ì‘ë‹µí–ˆëŠ”ì§€, ì˜¬ë°”ë¥¸ íŒŒì¼ì„ ì¸ìš©í–ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "view-search-results-code",
      "metadata": {},
      "outputs": [],
      "source": [
        "def display_thread_messages(thread_id):\n",
        "    try:\n",
        "        # Retrieve all messages in this conversation thread using the Azure AI Agent SDK\n",
        "        # Messages contain the back-and-forth between user and AI agent\n",
        "        messages = project_client.agents.list_messages(thread_id=thread_id)\n",
        "\n",
        "        # Display the conversation history in reverse chronological order (newest first)\n",
        "        print(\"\\nğŸ—£ï¸ Conversation so far:\")\n",
        "        for m in reversed(messages.data):\n",
        "            # Each message may have multiple content pieces\n",
        "            # We're interested in the text content (vs other types like images)\n",
        "            if m.content:\n",
        "                last_content = m.content[-1]\n",
        "                if hasattr(last_content, \"text\"):\n",
        "                    # Print who said what (ASSISTANT or USER) along with their message\n",
        "                    print(f\"{m.role.upper()}: {last_content.text.value}\\n\")\n",
        "\n",
        "        # The agent can cite specific passages from the uploaded documents\n",
        "        # Let's check if it referenced any files in its responses\n",
        "        print(\"\\nğŸ“ Checking for citations...\")\n",
        "        for c in messages.file_citation_annotations:\n",
        "            # Each citation includes the quoted text and which file it came from\n",
        "            # This helps users verify the agent's sources\n",
        "            print(f\"- Citation snippet: '{c.text}' from file ID: {c.file_citation['file_id']}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        # Gracefully handle any errors that might occur when displaying messages\n",
        "        print(f\"âŒ Error displaying messages: {e}\")\n",
        "\n",
        "# Display the conversation history for our search thread\n",
        "if search_thread:\n",
        "    display_thread_messages(search_thread.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cleanup",
      "metadata": {},
      "source": [
        "## 7. ì •ë¦¬ ë° ëª¨ë²” ì‚¬ë¡€ ğŸ§¹\n",
        "ì„ íƒì ìœ¼ë¡œ ë²¡í„° ìŠ¤í† ì–´, ì—…ë¡œë“œëœ íŒŒì¼ ë° ì—ì´ì „íŠ¸ë¥¼ ì œê±°í•©ë‹ˆë‹¤. í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œëŠ” ë” ì˜¤ë˜ ë³´ê´€í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ê·¸ ë™ì•ˆ ëª‡ ê°€ì§€ íŒì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤:\n",
        "\n",
        "1. **ë¦¬ì†ŒìŠ¤ ê´€ë¦¬**\n",
        "   - íŒŒì¼ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”í•˜ê³ , ì˜¤ë˜ë˜ê±°ë‚˜ ê´€ë ¨ ì—†ëŠ” íŒŒì¼ì„ ì •ê¸°ì ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”.\n",
        "   - í…ŒìŠ¤íŠ¸ ì—ì´ì „íŠ¸ë‚˜ ë²¡í„° ìŠ¤í† ì–´ëŠ” ì‘ì—…ì´ ëë‚˜ë©´ ì •ë¦¬í•˜ì„¸ìš”.\n",
        "\n",
        "2. **ê²€ìƒ‰ ì¿¼ë¦¬**\n",
        "   - ì •í™•í•œ ì¿¼ë¦¬ ë˜ëŠ” ì—¬ëŸ¬ ë¶€ë¶„ìœ¼ë¡œ êµ¬ì„±ëœ ì¿¼ë¦¬ë¥¼ ì œê³µí•˜ì„¸ìš”.\n",
        "   - ë™ì˜ì–´ ë˜ëŠ” ëŒ€ì²´ í‚¤ì›Œë“œë¥¼ ê³ ë ¤í•˜ì„¸ìš” (ì˜ˆë¥¼ ë“¤ì–´ \"gluten-free\" vs \"celiac\").\n",
        "   \n",
        "3. **ê±´ê°• ì •ë³´**\n",
        "   - í•­ìƒ ì˜ë£Œ ì „ë¬¸ê°€ê°€ ì•„ë‹˜ì„ ëª…ì‹œí•˜ì„¸ìš”.\n",
        "   - ì‚¬ìš©ìê°€ êµ¬ì²´ì ì¸ ì§„ë‹¨ì„ ìœ„í•´ ì˜ì‚¬ì˜ ì§„ì°°ì„ ë°›ë„ë¡ ê¶Œì¥í•˜ì„¸ìš”.\n",
        "\n",
        "4. **ì„±**\n",
        "   - ë²¡í„° ìŠ¤í† ì–´ í¬ê¸°ì˜ ë³€í™”ì— ì£¼ì˜í•˜ì„¸ìš”.\n",
        "   - `azure-ai-evaluation`ìœ¼ë¡œ ê²€ìƒ‰ ì •í™•ë„ë¥¼ í‰ê°€í•˜ì„¸ìš”!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cleanup-code",
      "metadata": {},
      "outputs": [],
      "source": [
        "def cleanup_all():\n",
        "    try:\n",
        "        # Check if we have a vector store and delete it\n",
        "        # Vector stores are where we store the embeddings (numerical representations) \n",
        "        # of our documents for semantic search\n",
        "        if 'vector_store' in globals() and vector_store:\n",
        "            project_client.agents.delete_vector_store(vector_store.id)\n",
        "            print(\"ğŸ—‘ï¸ Deleted vector store.\")\n",
        "\n",
        "        # Remove any files we uploaded to Azure AI Search\n",
        "        # These were the documents our agent used as its knowledge base\n",
        "        if 'file_ids' in globals() and file_ids:\n",
        "            for fid in file_ids:\n",
        "                project_client.agents.delete_file(fid)\n",
        "            print(\"ğŸ—‘ï¸ Deleted uploaded files from the service.\")\n",
        "\n",
        "        # Delete the AI agent we created\n",
        "        # This frees up resources since we're done with our demo\n",
        "        if 'health_agent' in globals() and health_agent:\n",
        "            project_client.agents.delete_agent(health_agent.id)\n",
        "            print(\"ğŸ—‘ï¸ Deleted health resource agent.\")\n",
        "\n",
        "        # Clean up any local files we created during the demo\n",
        "        # This keeps our workspace tidy\n",
        "        if 'sample_files' in globals() and sample_files:\n",
        "            for sf in sample_files:\n",
        "                if os.path.exists(sf):\n",
        "                    os.remove(sf)\n",
        "            print(\"ğŸ—‘ï¸ Deleted local sample files.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        # If anything goes wrong during cleanup, we'll see what happened\n",
        "        print(f\"âŒ Error during cleanup: {e}\")\n",
        "\n",
        "# Run our cleanup function to remove all resources we created\n",
        "# This is good practice in a tutorial/demo environment\n",
        "cleanup_all()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conclusion",
      "metadata": {},
      "source": [
        "# ì¶•í•˜í•©ë‹ˆë‹¤! ğŸ‰\n",
        "**ê±´ê°• ë¦¬ì†ŒìŠ¤ ê²€ìƒ‰ ì—ì´ì „íŠ¸**ë¥¼ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤:\n",
        "1. **ë²¡í„° ìŠ¤í† ì–´**ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒ˜í”Œ ë ˆì‹œí”¼ ë° ê°€ì´ë“œë¼ì¸ì„ ì €ì¥í•©ë‹ˆë‹¤.\n",
        "2. ì¿¼ë¦¬ì— ë‹µí•˜ê¸° ìœ„í•´ **ê²€ìƒ‰**í•©ë‹ˆë‹¤.\n",
        "3. ì‚¬ìš©ìì—ê²Œ ì „ë¬¸ê°€ì™€ ìƒë‹´í•  ê²ƒì„ ìƒê¸°ì‹œí‚¤ëŠ” **ë©´ì±… ì¡°í•­**ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
        "\n",
        "ê¸°ì—… ë¬¸ì„œ, ì œí’ˆ ì„¤ëª…ì„œ ë˜ëŠ” ë§ì¶¤í˜• ê±´ê°• ë¦¬ì†ŒìŠ¤ì— ì´ ì ‘ê·¼ ë°©ì‹ì„ ììœ ë¡­ê²Œ ì ìš©í•˜ì„¸ìš”.\n",
        "\n",
        "í–‰ë³µí•œ ê²€ìƒ‰ë˜ì„¸ìš”! ğŸ‰\n",
        "\n",
        "#### [4-bing_grounding.ipynb](4-bing_grounding.ipynb)ë¡œ ì´ë™í•©ë‹ˆë‹¤."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

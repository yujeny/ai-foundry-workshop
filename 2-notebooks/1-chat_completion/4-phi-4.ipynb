{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1e99a5b8",
      "metadata": {},
      "source": [
        "# 🍎 AIProjectClient에서 Phi-4 모델 사용 🍏\n",
        "\n",
        "**Phi-4**는 적은 비용으로 GPT-4o에 가까운 기능을 제공하는 것을 목표로 하는 차세대 개방형 모델로, 많은 기업 또는 개인 사용 사례에 이상적입니다. 특히 연쇄 추론과 RAG(검색 증강 세대) 시나리오에 적합합니다.\n",
        "\n",
        "이 노트북은 다음과 같이 진행됩니다:\n",
        "1. Azure AI 파운드리 환경에 맞게 `AIProjectClient`를 **초기화**합니다.\n",
        "2. `azure-ai-inference`를 사용하여 **Phi-4** 모델과 **채팅**합니다.\n",
        "3. 고지 사항 및 건강 Q&A가 포함된 건강 및 피트니스 예제를 **표시**합니다.\n",
        "4. 강력한 추론 기능을 갖춘 GPT-4에 대한 저렴한 대안을 이용할 수 있습니다. 🏋️\n",
        "\n",
        "> **면책조항**: 이것은 의학적 조언이 아닙니다. 전문가와 상담하시기 바랍니다..\n",
        "\n",
        "## 왜 Phi-4인가?\n",
        "Phi-4는 높은 추론 성능을 위해 선별된 데이터로 학습된 14B 파라미터 모델입니다.\n",
        "- **비용 효율적**: GPT-4 수준의 가격보다 저렴하게 많은 작업에서 GPT-4 수준의 성능을 얻을 수 있습니다.\n",
        "- **추론 및 RAG**: 연쇄 추론 단계 및 검색 증강 생성 워크플로우에 적합합니다.\n",
        "- **충분한 컨텍스트 윈도우**: 16K 토큰으로 더 많은 컨텍스트 또는 더 긴 사용자 대화가 가능합니다.\n",
        "\n",
        "<img src=\"./seq-diagrams/4-phi-4.png\" width=\"30%\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e93357dd",
      "metadata": {},
      "source": [
        "## 1. 설정\n",
        "\n",
        "아래에서 필요한 라이브러리를 설치하고 가져오겠습니다:\n",
        "- **azure-ai-projects**: `AIProjectClient`용\n",
        "- **azure-ai-inference**: 모델, 특히 채팅 완료를 호출하기 위한 라이브러리.\n",
        "- **azure-identity**: `DefaultAzureCredential`용\n",
        "\n",
        "`.env` 파일에 다음을 확인하세요:\n",
        "```bash\n",
        "PROJECT_CONNECTION_STRING=<your-conn-string>\n",
        "SERVERLESS_MODEL_NAME=phi-4\n",
        "```\n",
        "\n",
        "> **주**: 여기서 도움이 될 중요한 개념을 다루고 있으므로 [`3-basic-rag.ipynb`](./3-basic-rag.ipynb) 노트북을 완수하고 이 노트북을 수행하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b5634a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from pathlib import Path\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.ai.projects import AIProjectClient\n",
        "from azure.ai.inference.models import SystemMessage, UserMessage, AssistantMessage\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# Load environment variables\n",
        "notebook_path = Path().absolute()\n",
        "parent_dir = notebook_path.parent\n",
        "load_dotenv(parent_dir / '.env')\n",
        "\n",
        "conn_string = os.getenv(\"PROJECT_CONNECTION_STRING\")\n",
        "phi4_deployment = os.getenv(\"SERVERLESS_MODEL_NAME\", \"phi-4\")\n",
        "\n",
        "try:\n",
        "    project_client = AIProjectClient.from_connection_string(\n",
        "        credential=DefaultAzureCredential(),\n",
        "        conn_str=conn_string,\n",
        "    )\n",
        "    print(\"✅ AIProjectClient created successfully!\")\n",
        "except Exception as e:\n",
        "    print(\"❌ Error creating AIProjectClient:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "500d63ef",
      "metadata": {},
      "source": [
        "## 2. Phi-4와 채팅하기 🍏\n",
        "건강 및 피트니스 맥락에서 **Phi-4**를 사용한 간단한 대화를 시연해 보겠습니다. 어시스턴트의 역할을 명확히 하는 시스템 프롬프트를 정의하겠습니다. 그런 다음 몇 가지 사용자 질문을 해보겠습니다.\n",
        "\n",
        "> Phi-4는 연쇄 추론에 매우 적합하다는 것을 알 수 있습니다. 추론 단계를 설명해 보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bcc4772",
      "metadata": {},
      "outputs": [],
      "source": [
        "def chat_with_phi4(user_question, chain_of_thought=False):\n",
        "    \"\"\"Send a chat request to the Phi-4 model with optional chain-of-thought.\"\"\"\n",
        "    # We'll define a system message with disclaimers:\n",
        "    system_prompt = (\n",
        "        \"You are a Phi-4 AI assistant, focusing on health and fitness.\\n\"\n",
        "        \"Remind users that you are not a medical professional, but can provide general info.\\n\"\n",
        "    )\n",
        "\n",
        "    # We can optionally instruct the model to show chain-of-thought. (Use carefully in production.)\n",
        "    if chain_of_thought:\n",
        "        system_prompt += \"Please show your step-by-step reasoning in your answer.\\n\"\n",
        "\n",
        "    # We create messages for system + user.\n",
        "    system_msg = SystemMessage(content=system_prompt)\n",
        "    user_msg = UserMessage(content=user_question)\n",
        "\n",
        "    with project_client.inference.get_chat_completions_client() as chat_client:\n",
        "        response = chat_client.complete(\n",
        "            model=phi4_deployment,\n",
        "            messages=[system_msg, user_msg],\n",
        "            temperature=0.8,  # a bit creative\n",
        "            top_p=0.9,\n",
        "            max_tokens=400,\n",
        "        )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Example usage:\n",
        "question = \"I'm training for a 5K. Any tips on a weekly workout schedule?\"\n",
        "answer = chat_with_phi4(question, chain_of_thought=True)\n",
        "print(\"🗣️ User:\", question)\n",
        "print(\"🤖 Phi-4:\", answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc68c40d",
      "metadata": {},
      "source": [
        "## 3. RAG와 유사한 예제(스텁)\n",
        "Phi-4는 외부 컨텍스트를 제공하고 모델이 이를 추론하도록 하는 검색 증강 생성 시나리오에서도 탁월한 성능을 발휘합니다. 다음은 검색된 텍스트를 컨텍스트로 전달하는 방법을 보여주는 **스텁** 예제입니다.\n",
        "\n",
        "> 실제 시나리오에서는 관련 구절을 임베드하고 검색한 다음 사용자/시스템 메시지에 전달합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "419ea578",
      "metadata": {},
      "outputs": [],
      "source": [
        "def chat_with_phi4_rag(user_question, retrieved_doc):\n",
        "    \"\"\"Simulate an RAG flow by appending retrieved context to the system prompt.\"\"\"\n",
        "    system_prompt = (\n",
        "        \"You are Phi-4, helpful fitness AI.\\n\"\n",
        "        \"We have some context from the user's knowledge base: \\n\"\n",
        "        f\"{retrieved_doc}\\n\"\n",
        "        \"Please use this context to help your answer. If the context doesn't help, say so.\\n\"\n",
        "    )\n",
        "\n",
        "    system_msg = SystemMessage(content=system_prompt)\n",
        "    user_msg = UserMessage(content=user_question)\n",
        "\n",
        "    with project_client.inference.get_chat_completions_client() as chat_client:\n",
        "        response = chat_client.complete(\n",
        "            model=phi4_deployment,\n",
        "            messages=[system_msg, user_msg],\n",
        "            temperature=0.3,\n",
        "            max_tokens=300,\n",
        "        )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Let's define a dummy doc snippet:\n",
        "doc_snippet = \"Recommended to run 3 times per week and mix with cross-training.\\n\" \\\n",
        "              \"Include rest days or active recovery days for muscle repair.\"\n",
        "\n",
        "user_q = \"How often should I run weekly to prepare for a 5K?\"\n",
        "rag_answer = chat_with_phi4_rag(user_q, doc_snippet)\n",
        "print(\"🗣️ User:\", user_q)\n",
        "print(\"🤖 Phi-4 (RAG):\", rag_answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a33a375",
      "metadata": {},
      "source": [
        "## 4. 마무리 및 모범 사례\n",
        "1. **Chain-of-Thought**: 디버깅이나 특정 QA 작업에 유용하지만 최종 사용자에게 Chain-of-Thought를 공개하는 것에 유의하세요.r\n",
        "2. **RAG**: 검색 결과와 함께 `azure-ai-inference`를 사용하여 답변의 근거를 마련하세요.\n",
        "3. **OpenTelemetry**: 완전한 통합 가시성을 위해 선택적으로 `opentelemetry-sdk` 및 `azure-core-tracing-opentelemetry`를 통합합니다.\n",
        "4. **Evaluate**: 모델 성능을 측정하려면 `azure-ai-evaluation`을 사용합니다.\n",
        "5. **Cost & Performance**: Phi-4는 저렴한 비용으로 GPT-4에 가까운 성능을 제공하는 것을 목표로 합니다. 도메인 요구 사항에 맞게 평가하세요.\n",
        "\n",
        "## 🎉 축하합니다!\n",
        "방법을 확인하셨습니다:\n",
        "- `AIProjectClient` 및 `azure-ai-inference`를 **Phi-4**와 함께 사용하세요.\n",
        "- chain-of-thought을 사용하여 **chat** 흐름을 만듭니다.\n",
        "- RAG** 시나리오를 stub.\n",
        "\n",
        "> Happy hacking! 🏋️\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

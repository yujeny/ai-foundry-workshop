{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56be2132",
   "metadata": {},
   "source": [
    "# 🍎 AIProjectClient를 사용한 채팅 완료 🍏\n",
    "\n",
    "이 노트북에서는 **Azure AI Foundry SDK**를 사용하여 **채팅 완성(Chat Completion)**을 수행하는 방법을 보여드리겠습니다. **`azure-ai-projects`** 및 **`azure-ai-inference`** 패키지를 결합하여 다음과 같이 합니다:\n",
    "\n",
    "1. `AIProjectClient`를 **초기화**합니다.\n",
    "2. 직접 LLM 호출을 수행할 채팅 완료 클라이언트를 **가져옵니다**.\n",
    "3. **프롬프트 템플릿**을 **사용**하여 시스템 컨텍스트를 추가합니다.\n",
    "4. 건강 및 피트니스 테마로 사용자 프롬프트를 **보냅니다**.\n",
    "\n",
    "## 🏋️ 건강-피트니스 면책 조항\n",
    "> **이 예시는 데모용이며 실제 의학적 조언을 제공하지 않습니다**. 건강 또는 의료 관련 질문은 항상 전문가와 상담하세요.\n",
    "\n",
    "### 전제 조건\n",
    "이 노트북을 시작하기 전에 [README.md](../../README.md#-prerequisites)에 나열된 모든 사전 요구 사항을 완료했는지 확인하세요.\n",
    "\n",
    "그럼 시작해 보겠습니다! 🎉\n",
    "\n",
    "<img src=\"./seq-diagrams/1-chat.png\" width=\"30%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5fedcc",
   "metadata": {},
   "source": [
    "## 1. 초기 설정\n",
    "환경 변수를 로드하고, `AIProjectClient`를 만들고, `ChatCompletionsClient`를 가져옵니다. 또한 **프롬프트 템플릿**을 정의하여 시스템 메시지를 구성하는 방법을 보여줍니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dd1b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.inference.models import UserMessage, SystemMessage  # for chat messages\n",
    "\n",
    "# Load environment variables\n",
    "notebook_path = Path().absolute()\n",
    "parent_dir = notebook_path.parent\n",
    "load_dotenv(parent_dir / '.env')\n",
    "\n",
    "# Retrieve from environment\n",
    "connection_string = os.environ.get(\"PROJECT_CONNECTION_STRING\")\n",
    "model_deployment = os.environ.get(\"MODEL_DEPLOYMENT_NAME\")\n",
    "\n",
    "try:\n",
    "    # Create the project client\n",
    "    project_client = AIProjectClient.from_connection_string(\n",
    "        credential=DefaultAzureCredential(),\n",
    "        conn_str=connection_string,\n",
    "    )\n",
    "    print(\"✅ Successfully created AIProjectClient\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Error initializing client:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03c9a87",
   "metadata": {},
   "source": [
    "### 프롬프트 템플릿\n",
    "면책 조항을 제공하는 친절한 피트니스 도우미로서 컨텍스트를 설정하는 빠른 **시스템** 메시지를 정의하겠습니다.\n",
    "\n",
    "```txt\n",
    "SYSTEM PROMPT (template):\n",
    "You are FitChat GPT, a helpful fitness assistant.\n",
    "Always remind users: I'm not a medical professional.\n",
    "Be friendly, provide general advice.\n",
    "...\n",
    "```\n",
    "\n",
    "그런 다음 사용자 콘텐츠를 **사용자** 메시지로 전달합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab052b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll define a function that runs chat completions with a system prompt & user prompt\n",
    "def chat_with_fitness_assistant(user_input: str):\n",
    "    \"\"\"Use chat completions to get a response from our LLM, with system instructions.\"\"\"\n",
    "    # Our system message template\n",
    "    system_text = (\n",
    "        \"You are FitChat GPT, a friendly fitness assistant.\\n\"\n",
    "        \"Always remind users: I'm not a medical professional.\\n\"\n",
    "        \"Answer with empathy and disclaimers.\"\n",
    "    )\n",
    "\n",
    "    # We'll open the chat completions client\n",
    "    with project_client.inference.get_chat_completions_client() as chat_client:\n",
    "        # Construct messages: system + user\n",
    "        system_message = SystemMessage(content=system_text)\n",
    "        user_message = UserMessage(content=user_input)\n",
    "\n",
    "        # Send the request\n",
    "        response = chat_client.complete(\n",
    "            model=model_deployment,\n",
    "            messages=[system_message, user_message]\n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content  # simplest approach: get top choice's content\n",
    "\n",
    "print(\"Defined a helper function to do chat completions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273d7bdd",
   "metadata": {},
   "source": [
    "## 2. 채팅 완성 기능 사용해보기 🎉\n",
    "건강이나 피트니스에 관한 사용자 질문으로 함수를 호출하고 결과를 확인해 보겠습니다. 질문을 자유롭게 수정하거나 여러 번 실행해 보세요!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee675bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"How can I start a beginner workout routine at home?\"\n",
    "reply = chat_with_fitness_assistant(user_question)\n",
    "print(\"🗣️ User:\", user_question)\n",
    "print(\"🤖 Assistant:\", reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eff150",
   "metadata": {},
   "source": [
    "## 3. 다른 예제: 입력란이 있는 프롬프트 템플릿 📝\n",
    "조금 더 나아가 시스템 메시지에 자리 표시자를 추가할 수 있습니다. 예를 들어 **userName** 또는 **goal**이 있다고 가정해 보겠습니다. 최소한의 예시를 보여드리겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfec1e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_template(user_input: str, user_name: str, goal: str):\n",
    "    # Construct a system template with placeholders\n",
    "    system_template = (\n",
    "        \"You are FitChat GPT, an AI personal trainer for {name}.\\n\"\n",
    "        \"Your user wants to achieve: {goal}.\\n\"\n",
    "        \"Remind them you're not a medical professional. Offer friendly advice.\"\n",
    "    )\n",
    "\n",
    "    # Fill in placeholders\n",
    "    system_prompt = system_template.format(name=user_name, goal=goal)\n",
    "\n",
    "    with project_client.inference.get_chat_completions_client() as chat_client:\n",
    "        system_msg = SystemMessage(content=system_prompt)\n",
    "        user_msg = UserMessage(content=user_input)\n",
    "\n",
    "        response = chat_client.complete(\n",
    "            model=model_deployment,\n",
    "            messages=[system_msg, user_msg]\n",
    "        )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Let's try it out\n",
    "templated_user_input = \"What kind of home exercise do you recommend for a busy schedule?\"\n",
    "assistant_reply = chat_with_template(\n",
    "    templated_user_input,\n",
    "    user_name=\"Jordan\",\n",
    "    goal=\"increase muscle tone and endurance\"\n",
    ")\n",
    "print(\"🗣️ User:\", templated_user_input)\n",
    "print(\"🤖 Assistant:\", assistant_reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0066b883",
   "metadata": {},
   "source": [
    "## 🎉 축하합니다!\n",
    "Azure AI Foundry의 `AIProjectClient` 및 `azure-ai-inference`를 사용하여 **채팅 완료**를 성공적으로 수행했습니다. 또한 **프롬프트 템플릿**을 통합하여 시스템 지침을 맞춤화하는 방법도 살펴보았습니다.\n",
    "\n",
    "#### 워크샵의 다음 부분을 보려면 [2-embeddings.ipynb](2-embeddings.ipynb)로 이동하세요!  🎯"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
